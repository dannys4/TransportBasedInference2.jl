{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `/media/mat/HDD/AdaptiveTransportMap/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"/media/mat/HDD/AdaptiveTransportMap/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling AdaptiveTransportMap [bdf749b0-1400-4207-80d3-e689c0e3f03d]\n",
      "└ @ Base loading.jl:1260\n"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "using AdaptiveTransportMap\n",
    "using LinearAlgebra\n",
    "import LinearAlgebra: ldiv!, dot\n",
    "using Test\n",
    "using ForwardDiff\n",
    "using SpecialFunctions\n",
    "using Polynomials\n",
    "using BenchmarkTools\n",
    "using TransportMap\n",
    "using QuadGK\n",
    "using FastGaussQuadrature\n",
    "using AdaptiveTransportMap: derivative, vander, transform!, evaluate, ncoeff\n",
    "using DiffResults\n",
    "using Distributions\n",
    "using Random\n",
    "using LoopVectorization\n",
    "using Optim\n",
    "using Roots\n",
    "using NLsolve\n",
    "using Optim: InverseDiagonal#, ldiv!, dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[18]:13\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: norm(std(X'; dims = 2) - ones(Nx)) < 1.0e-10\n",
      "  DimensionMismatch(\"dimensions must match: a has dims (Base.OneTo(500), Base.OneTo(1)), b has dims (Base.OneTo(100),), mismatch at 1\")\n",
      "  Stacktrace:\n",
      "   [1] promote_shape at ./indices.jl:178 [inlined]\n",
      "   [2] promote_shape at ./indices.jl:169 [inlined]\n",
      "   [3] -(::Array{Float64,2}, ::Array{Float64,1}) at ./arraymath.jl:38\n",
      "   [4] top-level scope at In[18]:13\n",
      "   [5] eval at ./boot.jl:331 [inlined]\n",
      "   [6] softscope_include_string(::Module, ::String, ::String) at /home/mat/.julia/packages/SoftGlobalScope/cSbw5/src/SoftGlobalScope.jl:218\n",
      "   [7] execute_request(::ZMQ.Socket, ::IJulia.Msg) at /home/mat/.julia/packages/IJulia/DrVMH/src/execute_request.jl:67\n",
      "   [8] #invokelatest#1 at ./essentials.jl:712 [inlined]\n",
      "   [9] invokelatest at ./essentials.jl:711 [inlined]\n",
      "   [10] eventloop(::ZMQ.Socket) at /home/mat/.julia/packages/IJulia/DrVMH/src/eventloop.jl:8\n",
      "   [11] (::IJulia.var\"#15#18\")() at ./task.jl:358\n",
      "  \n"
     ]
    },
    {
     "ename": "Test.FallbackTestSetException",
     "evalue": "There was an error during testing",
     "output_type": "error",
     "traceback": [
      "There was an error during testing",
      "",
      "Stacktrace:",
      " [1] record(::Test.FallbackTestSet, ::Union{Test.Error, Test.Fail}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Test/src/Test.jl:737",
      " [2] do_test(::Test.ExecutionResult, ::Any) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Test/src/Test.jl:520",
      " [3] top-level scope at In[18]:13"
     ]
    }
   ],
   "source": [
    "    # Dense rescaling\n",
    "    Nx = 100\n",
    "    Ne = 500\n",
    "    ens = EnsembleState(Nx, Ne)\n",
    "\n",
    "    ens.S .= randn(Nx).+ randn(Nx, Ne) .* randn(Nx, Ne)\n",
    "    X = deepcopy(ens.S)\n",
    "    L = LinearTransform(X; diag = true)\n",
    "\n",
    "    AdaptiveTransportMap.transform!(L, X);\n",
    "\n",
    "    @test norm(mean(X;dims = 2))<1e-10\n",
    "    @test norm(  - ones(Nx))<1e-10\n",
    "\n",
    "#     AdaptiveTransportMap.itransform!(L, X)\n",
    "\n",
    "#     @test norm(mean(X;dims = 2) - mean(ens))<1e-10\n",
    "#     @test norm(cov(X')  - cov(ens))<1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500×1 Array{Float64,2}:\n",
       " 0.8101215623773982\n",
       " 1.162590278953438\n",
       " 0.8406826135213554\n",
       " 0.9024312887460753\n",
       " 0.9107346623500261\n",
       " 0.9546151445907091\n",
       " 0.9071210811677319\n",
       " 1.187432484267459\n",
       " 1.0250801129223708\n",
       " 0.9805963600090831\n",
       " 1.0551075540041086\n",
       " 1.1726245413799852\n",
       " 0.7384640022543452\n",
       " ⋮\n",
       " 1.0386652205108282\n",
       " 0.8434050507745406\n",
       " 0.8759666868957762\n",
       " 0.9665224711918406\n",
       " 0.7651309274662362\n",
       " 1.2410904711733703\n",
       " 0.9983748546166819\n",
       " 0.9111262849973125\n",
       " 1.1480084986213006\n",
       " 0.7011055266686552\n",
       " 0.963754894251547\n",
       " 0.9518569861301202"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std('; dims = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1m!\u001b[22m sp\u001b[0m\u001b[1ml\u001b[22mit\u001b[0m\u001b[1md\u001b[22mr\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mv\u001b[22me\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "ldiv!(Y, A, B) -> Y\n",
       "\\end{verbatim}\n",
       "Compute \\texttt{A {\\textbackslash} B} in-place and store the result in \\texttt{Y}, returning the result.\n",
       "\n",
       "The argument \\texttt{A} should \\emph{not} be a matrix.  Rather, instead of matrices it should be a factorization object (e.g. produced by \\href{@ref}{\\texttt{factorize}} or \\href{@ref}{\\texttt{cholesky}}). The reason for this is that factorization itself is both expensive and typically allocates memory (although it can also be done in-place via, e.g., \\href{@ref}{\\texttt{lu!}}), and performance-critical situations requiring \\texttt{ldiv!} usually also require fine-grained control over the factorization of \\texttt{A}.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> A = [1 2.2 4; 3.1 0.2 3; 4 1 2];\n",
       "\n",
       "julia> X = [1; 2.5; 3];\n",
       "\n",
       "julia> Y = zero(X);\n",
       "\n",
       "julia> ldiv!(Y, qr(A), X);\n",
       "\n",
       "julia> Y\n",
       "3-element Array{Float64,1}:\n",
       "  0.7128099173553719\n",
       " -0.051652892561983674\n",
       "  0.10020661157024757\n",
       "\n",
       "julia> A\\X\n",
       "3-element Array{Float64,1}:\n",
       "  0.7128099173553719\n",
       " -0.05165289256198333\n",
       "  0.10020661157024785\n",
       "\\end{verbatim}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "ldiv!(A, B)\n",
       "\\end{verbatim}\n",
       "Compute \\texttt{A {\\textbackslash} B} in-place and overwriting \\texttt{B} to store the result.\n",
       "\n",
       "The argument \\texttt{A} should \\emph{not} be a matrix.  Rather, instead of matrices it should be a factorization object (e.g. produced by \\href{@ref}{\\texttt{factorize}} or \\href{@ref}{\\texttt{cholesky}}). The reason for this is that factorization itself is both expensive and typically allocates memory (although it can also be done in-place via, e.g., \\href{@ref}{\\texttt{lu!}}), and performance-critical situations requiring \\texttt{ldiv!} usually also require fine-grained control over the factorization of \\texttt{A}.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> A = [1 2.2 4; 3.1 0.2 3; 4 1 2];\n",
       "\n",
       "julia> X = [1; 2.5; 3];\n",
       "\n",
       "julia> Y = copy(X);\n",
       "\n",
       "julia> ldiv!(qr(A), X);\n",
       "\n",
       "julia> X\n",
       "3-element Array{Float64,1}:\n",
       "  0.7128099173553719\n",
       " -0.051652892561983674\n",
       "  0.10020661157024757\n",
       "\n",
       "julia> A\\Y\n",
       "3-element Array{Float64,1}:\n",
       "  0.7128099173553719\n",
       " -0.05165289256198333\n",
       "  0.10020661157024785\n",
       "\\end{verbatim}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "ldiv!(a::Number, B::AbstractArray)\n",
       "\\end{verbatim}\n",
       "Divide each entry in an array \\texttt{B} by a scalar \\texttt{a} overwriting \\texttt{B} in-place.  Use \\href{@ref}{\\texttt{rdiv!}} to divide scalar from right.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> B = [1.0 2.0; 3.0 4.0]\n",
       "2×2 Array{Float64,2}:\n",
       " 1.0  2.0\n",
       " 3.0  4.0\n",
       "\n",
       "julia> ldiv!(2.0, B)\n",
       "2×2 Array{Float64,2}:\n",
       " 0.5  1.0\n",
       " 1.5  2.0\n",
       "\\end{verbatim}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "Solve Hy = rhs for a non-square Hessenberg matrix. Note that \\texttt{H} is also modified as is it converted to an upper triangular matrix via Given's rotations\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "ldiv!(Y, A, B) -> Y\n",
       "```\n",
       "\n",
       "Compute `A \\ B` in-place and store the result in `Y`, returning the result.\n",
       "\n",
       "The argument `A` should *not* be a matrix.  Rather, instead of matrices it should be a factorization object (e.g. produced by [`factorize`](@ref) or [`cholesky`](@ref)). The reason for this is that factorization itself is both expensive and typically allocates memory (although it can also be done in-place via, e.g., [`lu!`](@ref)), and performance-critical situations requiring `ldiv!` usually also require fine-grained control over the factorization of `A`.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> A = [1 2.2 4; 3.1 0.2 3; 4 1 2];\n",
       "\n",
       "julia> X = [1; 2.5; 3];\n",
       "\n",
       "julia> Y = zero(X);\n",
       "\n",
       "julia> ldiv!(Y, qr(A), X);\n",
       "\n",
       "julia> Y\n",
       "3-element Array{Float64,1}:\n",
       "  0.7128099173553719\n",
       " -0.051652892561983674\n",
       "  0.10020661157024757\n",
       "\n",
       "julia> A\\X\n",
       "3-element Array{Float64,1}:\n",
       "  0.7128099173553719\n",
       " -0.05165289256198333\n",
       "  0.10020661157024785\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "ldiv!(A, B)\n",
       "```\n",
       "\n",
       "Compute `A \\ B` in-place and overwriting `B` to store the result.\n",
       "\n",
       "The argument `A` should *not* be a matrix.  Rather, instead of matrices it should be a factorization object (e.g. produced by [`factorize`](@ref) or [`cholesky`](@ref)). The reason for this is that factorization itself is both expensive and typically allocates memory (although it can also be done in-place via, e.g., [`lu!`](@ref)), and performance-critical situations requiring `ldiv!` usually also require fine-grained control over the factorization of `A`.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> A = [1 2.2 4; 3.1 0.2 3; 4 1 2];\n",
       "\n",
       "julia> X = [1; 2.5; 3];\n",
       "\n",
       "julia> Y = copy(X);\n",
       "\n",
       "julia> ldiv!(qr(A), X);\n",
       "\n",
       "julia> X\n",
       "3-element Array{Float64,1}:\n",
       "  0.7128099173553719\n",
       " -0.051652892561983674\n",
       "  0.10020661157024757\n",
       "\n",
       "julia> A\\Y\n",
       "3-element Array{Float64,1}:\n",
       "  0.7128099173553719\n",
       " -0.05165289256198333\n",
       "  0.10020661157024785\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "ldiv!(a::Number, B::AbstractArray)\n",
       "```\n",
       "\n",
       "Divide each entry in an array `B` by a scalar `a` overwriting `B` in-place.  Use [`rdiv!`](@ref) to divide scalar from right.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> B = [1.0 2.0; 3.0 4.0]\n",
       "2×2 Array{Float64,2}:\n",
       " 1.0  2.0\n",
       " 3.0  4.0\n",
       "\n",
       "julia> ldiv!(2.0, B)\n",
       "2×2 Array{Float64,2}:\n",
       " 0.5  1.0\n",
       " 1.5  2.0\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "Solve Hy = rhs for a non-square Hessenberg matrix. Note that `H` is also modified as is it converted to an upper triangular matrix via Given's rotations\n"
      ],
      "text/plain": [
       "\u001b[36m  ldiv!(Y, A, B) -> Y\u001b[39m\n",
       "\n",
       "  Compute \u001b[36mA \\ B\u001b[39m in-place and store the result in \u001b[36mY\u001b[39m, returning the result.\n",
       "\n",
       "  The argument \u001b[36mA\u001b[39m should \u001b[4mnot\u001b[24m be a matrix. Rather, instead of matrices it should\n",
       "  be a factorization object (e.g. produced by \u001b[36mfactorize\u001b[39m or \u001b[36mcholesky\u001b[39m). The\n",
       "  reason for this is that factorization itself is both expensive and typically\n",
       "  allocates memory (although it can also be done in-place via, e.g., \u001b[36mlu!\u001b[39m), and\n",
       "  performance-critical situations requiring \u001b[36mldiv!\u001b[39m usually also require\n",
       "  fine-grained control over the factorization of \u001b[36mA\u001b[39m.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> A = [1 2.2 4; 3.1 0.2 3; 4 1 2];\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> X = [1; 2.5; 3];\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> Y = zero(X);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> ldiv!(Y, qr(A), X);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> Y\u001b[39m\n",
       "\u001b[36m  3-element Array{Float64,1}:\u001b[39m\n",
       "\u001b[36m    0.7128099173553719\u001b[39m\n",
       "\u001b[36m   -0.051652892561983674\u001b[39m\n",
       "\u001b[36m    0.10020661157024757\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> A\\X\u001b[39m\n",
       "\u001b[36m  3-element Array{Float64,1}:\u001b[39m\n",
       "\u001b[36m    0.7128099173553719\u001b[39m\n",
       "\u001b[36m   -0.05165289256198333\u001b[39m\n",
       "\u001b[36m    0.10020661157024785\u001b[39m\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  ldiv!(A, B)\u001b[39m\n",
       "\n",
       "  Compute \u001b[36mA \\ B\u001b[39m in-place and overwriting \u001b[36mB\u001b[39m to store the result.\n",
       "\n",
       "  The argument \u001b[36mA\u001b[39m should \u001b[4mnot\u001b[24m be a matrix. Rather, instead of matrices it should\n",
       "  be a factorization object (e.g. produced by \u001b[36mfactorize\u001b[39m or \u001b[36mcholesky\u001b[39m). The\n",
       "  reason for this is that factorization itself is both expensive and typically\n",
       "  allocates memory (although it can also be done in-place via, e.g., \u001b[36mlu!\u001b[39m), and\n",
       "  performance-critical situations requiring \u001b[36mldiv!\u001b[39m usually also require\n",
       "  fine-grained control over the factorization of \u001b[36mA\u001b[39m.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> A = [1 2.2 4; 3.1 0.2 3; 4 1 2];\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> X = [1; 2.5; 3];\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> Y = copy(X);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> ldiv!(qr(A), X);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> X\u001b[39m\n",
       "\u001b[36m  3-element Array{Float64,1}:\u001b[39m\n",
       "\u001b[36m    0.7128099173553719\u001b[39m\n",
       "\u001b[36m   -0.051652892561983674\u001b[39m\n",
       "\u001b[36m    0.10020661157024757\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> A\\Y\u001b[39m\n",
       "\u001b[36m  3-element Array{Float64,1}:\u001b[39m\n",
       "\u001b[36m    0.7128099173553719\u001b[39m\n",
       "\u001b[36m   -0.05165289256198333\u001b[39m\n",
       "\u001b[36m    0.10020661157024785\u001b[39m\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  ldiv!(a::Number, B::AbstractArray)\u001b[39m\n",
       "\n",
       "  Divide each entry in an array \u001b[36mB\u001b[39m by a scalar \u001b[36ma\u001b[39m overwriting \u001b[36mB\u001b[39m in-place. Use\n",
       "  \u001b[36mrdiv!\u001b[39m to divide scalar from right.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> B = [1.0 2.0; 3.0 4.0]\u001b[39m\n",
       "\u001b[36m  2×2 Array{Float64,2}:\u001b[39m\n",
       "\u001b[36m   1.0  2.0\u001b[39m\n",
       "\u001b[36m   3.0  4.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> ldiv!(2.0, B)\u001b[39m\n",
       "\u001b[36m  2×2 Array{Float64,2}:\u001b[39m\n",
       "\u001b[36m   0.5  1.0\u001b[39m\n",
       "\u001b[36m   1.5  2.0\u001b[39m\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "  Solve Hy = rhs for a non-square Hessenberg matrix. Note that \u001b[36mH\u001b[39m is also\n",
       "  modified as is it converted to an upper triangular matrix via Given's\n",
       "  rotations"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?ldiv!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(cholesky(cov(ens)).L)<:LowerTriangular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1my\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1m!\u001b[22m unsafe_\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1my\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1m!\u001b[22m \u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1my\u001b[22m_\u001b[0m\u001b[1mt\u001b[22mransp\u001b[0m\u001b[1mo\u001b[22mse\u001b[0m\u001b[1m!\u001b[22m FamilyS\u001b[0m\u001b[1mc\u001b[22maledPr\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mP\u001b[22mol\u001b[0m\u001b[1my\u001b[22mHermi\u001b[0m\u001b[1mt\u001b[22me\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "copyto!(dest, do, src, so, N)\n",
       "\\end{verbatim}\n",
       "Copy \\texttt{N} elements from collection \\texttt{src} starting at offset \\texttt{so}, to array \\texttt{dest} starting at offset \\texttt{do}. Return \\texttt{dest}.\n",
       "\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "copyto!(dest::AbstractArray, src) -> dest\n",
       "\\end{verbatim}\n",
       "Copy all elements from collection \\texttt{src} to array \\texttt{dest}, whose length must be greater than or equal to the length \\texttt{n} of \\texttt{src}. The first \\texttt{n} elements of \\texttt{dest} are overwritten, the other elements are left untouched.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> x = [1., 0., 3., 0., 5.];\n",
       "\n",
       "julia> y = zeros(7);\n",
       "\n",
       "julia> copyto!(y, x);\n",
       "\n",
       "julia> y\n",
       "7-element Array{Float64,1}:\n",
       " 1.0\n",
       " 0.0\n",
       " 3.0\n",
       " 0.0\n",
       " 5.0\n",
       " 0.0\n",
       " 0.0\n",
       "\\end{verbatim}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "copyto!(dest, Rdest::CartesianIndices, src, Rsrc::CartesianIndices) -> dest\n",
       "\\end{verbatim}\n",
       "Copy the block of \\texttt{src} in the range of \\texttt{Rsrc} to the block of \\texttt{dest} in the range of \\texttt{Rdest}. The sizes of the two regions must match.\n",
       "\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "copyto!(dest::AbstractMatrix, src::UniformScaling)\n",
       "\\end{verbatim}\n",
       "Copies a \\href{@ref}{\\texttt{UniformScaling}} onto a matrix.\n",
       "\n",
       "\\begin{quote}\n",
       "\\textbf{compat}\n",
       "\n",
       "Julia 1.1\n",
       "\n",
       "In Julia 1.0 this method only supported a square destination matrix. Julia 1.1. added support for a rectangular matrix.\n",
       "\n",
       "\\end{quote}\n"
      ],
      "text/markdown": [
       "```\n",
       "copyto!(dest, do, src, so, N)\n",
       "```\n",
       "\n",
       "Copy `N` elements from collection `src` starting at offset `so`, to array `dest` starting at offset `do`. Return `dest`.\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "copyto!(dest::AbstractArray, src) -> dest\n",
       "```\n",
       "\n",
       "Copy all elements from collection `src` to array `dest`, whose length must be greater than or equal to the length `n` of `src`. The first `n` elements of `dest` are overwritten, the other elements are left untouched.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> x = [1., 0., 3., 0., 5.];\n",
       "\n",
       "julia> y = zeros(7);\n",
       "\n",
       "julia> copyto!(y, x);\n",
       "\n",
       "julia> y\n",
       "7-element Array{Float64,1}:\n",
       " 1.0\n",
       " 0.0\n",
       " 3.0\n",
       " 0.0\n",
       " 5.0\n",
       " 0.0\n",
       " 0.0\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "copyto!(dest, Rdest::CartesianIndices, src, Rsrc::CartesianIndices) -> dest\n",
       "```\n",
       "\n",
       "Copy the block of `src` in the range of `Rsrc` to the block of `dest` in the range of `Rdest`. The sizes of the two regions must match.\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "copyto!(dest::AbstractMatrix, src::UniformScaling)\n",
       "```\n",
       "\n",
       "Copies a [`UniformScaling`](@ref) onto a matrix.\n",
       "\n",
       "!!! compat \"Julia 1.1\"\n",
       "    In Julia 1.0 this method only supported a square destination matrix. Julia 1.1. added support for a rectangular matrix.\n",
       "\n"
      ],
      "text/plain": [
       "\u001b[36m  copyto!(dest, do, src, so, N)\u001b[39m\n",
       "\n",
       "  Copy \u001b[36mN\u001b[39m elements from collection \u001b[36msrc\u001b[39m starting at offset \u001b[36mso\u001b[39m, to array \u001b[36mdest\u001b[39m\n",
       "  starting at offset \u001b[36mdo\u001b[39m. Return \u001b[36mdest\u001b[39m.\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  copyto!(dest::AbstractArray, src) -> dest\u001b[39m\n",
       "\n",
       "  Copy all elements from collection \u001b[36msrc\u001b[39m to array \u001b[36mdest\u001b[39m, whose length must be\n",
       "  greater than or equal to the length \u001b[36mn\u001b[39m of \u001b[36msrc\u001b[39m. The first \u001b[36mn\u001b[39m elements of \u001b[36mdest\u001b[39m\n",
       "  are overwritten, the other elements are left untouched.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> x = [1., 0., 3., 0., 5.];\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> y = zeros(7);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> copyto!(y, x);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> y\u001b[39m\n",
       "\u001b[36m  7-element Array{Float64,1}:\u001b[39m\n",
       "\u001b[36m   1.0\u001b[39m\n",
       "\u001b[36m   0.0\u001b[39m\n",
       "\u001b[36m   3.0\u001b[39m\n",
       "\u001b[36m   0.0\u001b[39m\n",
       "\u001b[36m   5.0\u001b[39m\n",
       "\u001b[36m   0.0\u001b[39m\n",
       "\u001b[36m   0.0\u001b[39m\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  copyto!(dest, Rdest::CartesianIndices, src, Rsrc::CartesianIndices) -> dest\u001b[39m\n",
       "\n",
       "  Copy the block of \u001b[36msrc\u001b[39m in the range of \u001b[36mRsrc\u001b[39m to the block of \u001b[36mdest\u001b[39m in the range\n",
       "  of \u001b[36mRdest\u001b[39m. The sizes of the two regions must match.\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  copyto!(dest::AbstractMatrix, src::UniformScaling)\u001b[39m\n",
       "\n",
       "  Copies a \u001b[36mUniformScaling\u001b[39m onto a matrix.\n",
       "\n",
       "\u001b[39m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[1mJulia 1.1\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  In Julia 1.0 this method only supported a square destination\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  matrix. Julia 1.1. added support for a rectangular matrix."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hessian computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nx = 4\n",
    "m = 10\n",
    "B = MultiBasis(CstProHermite(m; scaled =true), Nx)\n",
    "\n",
    "Nψ = 14\n",
    "# idx = rand(0:5,Nψ, Nx)\n",
    "idx =Matrix([5  2  5  3;\n",
    "             0  2  2  5;\n",
    "             5  4  3  4;\n",
    "             4  1  3  1;\n",
    "             3  2  4  5;\n",
    "             0  3  3  3;\n",
    "             4  2  0  0;\n",
    "             2  0  2  4;\n",
    "             4  4  0  5;\n",
    "             0  4  0  2;\n",
    "             4  5  5  5;\n",
    "             0  1  2  3;\n",
    "             4  2  4  0;\n",
    "             4  3  2  3]);\n",
    "\n",
    "\n",
    "coeff = [  2.421476831418713;\n",
    "          0.23398851530507098;\n",
    "         -0.5285368375369742;\n",
    "          0.8947095708709891;\n",
    "         -0.688462862924509;\n",
    "          0.23331743780756214;\n",
    "          2.0098809355359006;\n",
    "          1.1243983698817437;\n",
    "         -0.18373487759949592;\n",
    "          0.24787268168991677;\n",
    "          0.9041136183543212;\n",
    "          1.9776434399606355;\n",
    "          1.1972246121155632;\n",
    "          0.3847306368698849]\n",
    "\n",
    "f = ExpandedFunction(B, idx, coeff)\n",
    "\n",
    "fp = ParametricFunction(f)\n",
    "R = IntegratedFunction(fp)\n",
    "H = HermiteMapk(R; α = 1e-6);\n",
    "Ne = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14×1 Array{Int64,2}:\n",
       " 15\n",
       "  9\n",
       " 16\n",
       "  9\n",
       " 14\n",
       "  9\n",
       "  6\n",
       "  8\n",
       " 13\n",
       "  6\n",
       " 19\n",
       "  6\n",
       " 10\n",
       " 12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(idx;dims = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.002007 seconds (1.53 k allocations: 2.742 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "precond! (generic function with 2 methods)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = randn(Nx, Ne) .* randn(Nx, Ne) \n",
    "S = Storage(H.I.f, X; hess = false);\n",
    "\n",
    "J = 0.0\n",
    "dJ = zeros(Nψ)\n",
    "d2J = zeros(Nψ, Nψ)\n",
    "\n",
    "@time negative_log_likelihood!(J, dJ, coeff, S, H, X)\n",
    "\n",
    "precond!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  104.624 ms (130849 allocations: 233.12 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.479295e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 1.24e-05 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 1.82e-06 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 1.87e-13 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 1.26e-13 ≰ 0.0e+00\n",
       "    |g(x)|                 = 2.84e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    28\n",
       "    f(x) calls:    85\n",
       "    ∇f(x) calls:   85\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!($S, $H, $X)), $coeff, Optim.LBFGS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "error in method definition: function LinearAlgebra.ldiv! must be explicitly imported to be extended",
     "output_type": "error",
     "traceback": [
      "error in method definition: function LinearAlgebra.ldiv! must be explicitly imported to be extended",
      "",
      "Stacktrace:",
      " [1] top-level scope at none:0",
      " [2] top-level scope at In[26]:10"
     ]
    }
   ],
   "source": [
    "struct Preconditioner\n",
    "    P::Symmetric{Float64}\n",
    "    \n",
    "    F::Cholesky{Float64, Matrix{Float64}}\n",
    "end\n",
    "\n",
    "function Preconditioner(P::Matrix{Float64})\n",
    "    return Preconditioner(Symmetric(P), cholesky(Symmetric(P)))\n",
    "end\n",
    "\n",
    "ldiv!(x, P::Preconditioner, b) = copyto!(x, P.F \\ b)\n",
    "dot(A::Array, P::Preconditioner, B::Vector) = dot(A, P.P, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# res = Optim.optimize(Optim.only_fg!(negative_loglikelihood!(S, H, X)), coeff, \n",
    "#             Optim.LBFGS(P = Preconditioner(precond)))#, precondprep = (P, x) -> precond!(S, H, X)(P, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  104.817 ms (130849 allocations: 233.12 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.479295e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 1.24e-05 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 1.82e-06 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 1.87e-13 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 1.26e-13 ≰ 0.0e+00\n",
       "    |g(x)|                 = 2.84e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    28\n",
       "    f(x) calls:    85\n",
       "    ∇f(x) calls:   85\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!($S, $H, $X)), $coeff, Optim.LBFGS())#, precondprep = (P, x) -> Preconditioner(precond!($S, $H, $X)($P.P.data, x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.479295e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 6.21e-05 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 9.10e-06 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 7.68e-13 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 5.19e-13 ≰ 0.0e+00\n",
       "    |g(x)|                 = 3.43e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    8\n",
       "    f(x) calls:    17\n",
       "    ∇f(x) calls:   17\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precond = zeros(Nψ, Nψ)\n",
    "coeff0 = randn(Nψ)\n",
    "precond!(precond, coeff, S, H, X)\n",
    "P = Preconditioner(precond)\n",
    "\n",
    "res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!(S, H, X)), coeff0, Optim.LBFGS(; m = 20, P = Preconditioner(precond)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14-element Array{Float64,1}:\n",
       "  0.2042411208812283\n",
       " -0.160665456718217\n",
       "  5.371746068389059\n",
       " -0.19909085135432283\n",
       "  6.822999267856531\n",
       " -0.14374191048398882\n",
       " -0.3861327468309733\n",
       "  0.788767701800107\n",
       "  2.22362622541736\n",
       " -0.9700837073808384\n",
       "  2.7757966850015574\n",
       "  0.04063103525990578\n",
       "  1.7876303361723063\n",
       " -1.6264347964407893"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Optim.minimizer(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  72.319 ms (38554 allocations: 68.59 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.479295e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 8.58e-05 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 1.26e-05 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 1.74e-12 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 1.18e-12 ≰ 0.0e+00\n",
       "    |g(x)|                 = 5.12e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    8\n",
       "    f(x) calls:    17\n",
       "    ∇f(x) calls:   17\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!($S, $H, $X)), $coeff, \n",
    "            Optim.LBFGS(; m = 20, P = Preconditioner($precond), precondprep = (P, x) -> Preconditioner(precond!($S, $H, $X)($P.P.data, x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  19.128 ms (26245 allocations: 46.64 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.479295e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 8.58e-05 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 1.26e-05 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 1.74e-12 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 1.18e-12 ≰ 0.0e+00\n",
       "    |g(x)|                 = 5.12e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    8\n",
       "    f(x) calls:    17\n",
       "    ∇f(x) calls:   17\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!($S, $H, $X)), $coeff, \n",
    "            Optim.LBFGS(P = Preconditioner($precond)))#, precondprep = (P, x) -> Preconditioner(precond!($S, $H, $X)($P.P.data, x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  19.342 ms (26265 allocations: 46.64 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.479295e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 8.58e-05 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 1.26e-05 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 1.74e-12 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 1.18e-12 ≰ 0.0e+00\n",
       "    |g(x)|                 = 5.12e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    8\n",
       "    f(x) calls:    17\n",
       "    ∇f(x) calls:   17\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!($S, $H, $X)), $coeff, \n",
    "            Optim.LBFGS(; m = 20, P = Preconditioner($precond)))#, precondprep = (P, x) -> Preconditioner(precond!(S, H, X)(P.P.data, x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  19.304 ms (26265 allocations: 46.64 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.479295e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 8.58e-05 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 1.26e-05 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 1.74e-12 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 1.18e-12 ≰ 0.0e+00\n",
       "    |g(x)|                 = 5.12e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    8\n",
       "    f(x) calls:    17\n",
       "    ∇f(x) calls:   17\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!($S, $H, $X)), $coeff, \n",
    "            Optim.LBFGS(; m = 20, P = Preconditioner($precond)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dot (generic function with 40 methods)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagprecond = zeros(Nψ)\n",
    "coeff0 = randn(Nψ)\n",
    "diagprecond!(diagprecond, coeff, S, H, X)\n",
    "D = Optim.InverseDiagonal(diagprecond)\n",
    "\n",
    "ldiv!(out::Array, P::Optim.InverseDiagonal, A::Array) = copyto!(out, A .* P.diag)\n",
    "dot(A::Array, P::Optim.InverseDiagonal, B::Vector) = dot(A, B ./ P.diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14-element Array{Float64,1}:\n",
       " 0.00012403916115351907\n",
       " 0.000914061082337064\n",
       " 4.223509631951479e-5\n",
       " 0.0010497362861250537\n",
       " 9.846338287295053e-5\n",
       " 0.0023101801954228643\n",
       " 0.006057967285600174\n",
       " 0.000385561839624177\n",
       " 0.0005285393135169043\n",
       " 0.003055127424459309\n",
       " 6.995783516676906e-5\n",
       " 0.003976096151961689\n",
       " 0.0004067998335964076\n",
       " 0.000124219015787626"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagprecond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.479295e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 6.88e-05 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 1.01e-05 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 8.34e-13 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 5.63e-13 ≰ 0.0e+00\n",
       "    |g(x)|                 = 9.72e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    11\n",
       "    f(x) calls:    23\n",
       "    ∇f(x) calls:   23\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!(S, H, X)), coeff, \n",
    "            Optim.LBFGS(; m = 20, P = Diagonal(diagprecond)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25.826 ms (35493 allocations: 63.09 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.479295e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 6.88e-05 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 1.01e-05 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 8.34e-13 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 5.63e-13 ≰ 0.0e+00\n",
       "    |g(x)|                 = 9.72e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    11\n",
       "    f(x) calls:    23\n",
       "    ∇f(x) calls:   23\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!($S, $H, $X)), $coeff, \n",
    "            Optim.LBFGS(; m = 20, P = Diagonal($diagprecond)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.479295e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Nonlinear GMRES preconditioned with Gradient Descent\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 3.87e-05 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 5.68e-06 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 2.85e-13 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 1.93e-13 ≰ 0.0e+00\n",
       "    |g(x)|                 = 5.95e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   1  (vs limit Inf)\n",
       "    Iterations:    32\n",
       "    f(x) calls:    123\n",
       "    ∇f(x) calls:   123\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!(S, H, X)), zeros(Nψ), Optim.NGMRES())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.519 s (3527117 allocations: 6.96 GiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: failure (reached maximum number of iterations)\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.572975e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Accelerated Gradient Descent\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 4.30e-04 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 1.07e-04 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 2.20e-09 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 1.40e-09 ≰ 0.0e+00\n",
       "    |g(x)|                 = 1.35e-05 ≰ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   4  (vs limit Inf)\n",
       "    Iterations:    1000\n",
       "    f(x) calls:    3295\n",
       "    ∇f(x) calls:   3295\n"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!($S, $H, $X)), $coeff, Optim.AcceleratedGradientDescent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MomentumGradientDescent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3784285990365932"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = randn(Nx, Ne) .* randn(Nx, Ne) \n",
    "S = Storage(H.I.f, X);\n",
    "\n",
    "J = 0.0\n",
    "dJ = zeros(Nψ)\n",
    "d2J = zeros(Nψ, Nψ)\n",
    "hess_negative_log_likelihood!(J, dJ, d2J, coeff, S, H, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Array{Float64,1}:\n",
       " -0.647941708993688\n",
       "  0.01751723817324542\n",
       "  0.12943970119038775\n",
       "  0.0033091844731214684\n",
       " -0.00031264752126695754\n",
       "  0.03545495128594644\n",
       " -0.0062483204244866645\n",
       " -0.028569877746525366\n",
       " -0.0008423358431159828\n",
       " -0.0033284486942029698\n",
       " -0.005733695198669693"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  193.793 ms (82746 allocations: 143.66 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.341428e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Newton's Method (Trust Region)\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 1.16e-05 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 1.01e-06 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 1.38e-13 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 1.03e-13 ≰ 0.0e+00\n",
       "    |g(x)|                 = 2.62e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    28\n",
       "    f(x) calls:    29\n",
       "    ∇f(x) calls:   29\n",
       "    ∇²f(x) calls:  23\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime res = Optim.optimize(Optim.only_fgh!(hess_negative_log_likelihood!($S, $H, $X)), $coeff, Optim.NewtonTrustRegion())\n",
    "# coeffopt = Optim.minimizer(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.025023 seconds (17.23 k allocations: 44.434 MiB, 25.59% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.450904e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Newton's Method (Trust Region)\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 3.17e-04 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 2.29e-04 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 1.02e-11 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 7.03e-12 ≰ 0.0e+00\n",
       "    |g(x)|                 = 1.89e-13 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    4\n",
       "    f(x) calls:    5\n",
       "    ∇f(x) calls:   5\n",
       "    ∇²f(x) calls:  4\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time res = Optim.optimize(Optim.only_fgh!(hess_negative_log_likelihood!(S, H, X)), coeff, Optim.NewtonTrustRegion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     1.298813e+00\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 4.47e-06 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 4.06e-07 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 5.15e-14 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 3.97e-14 ≰ 0.0e+00\n",
       "    |g(x)|                 = 6.45e-10 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    19\n",
       "    f(x) calls:    58\n",
       "    ∇f(x) calls:   58\n"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!(S, H, X)), coeff, Optim.LBFGS())\n",
    "# coeffopt = Optim.minimizer(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000169 seconds (793 allocations: 47.328 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.137129544913297"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time negative_log_likelihood!(J, dJ, coeff, S, H, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx = 10\n",
    "\n",
    "m = 20\n",
    "\n",
    "Ne = 1000\n",
    "# ens = EnsembleState(Nx, Ne)\n",
    "\n",
    "# ens.S .=  [0.267333   1.43021;\n",
    "#           0.364979   0.607224;\n",
    "#          -1.23693    0.249277;\n",
    "#          -2.0526     0.915629;\n",
    "#          -0.182465   0.415874;\n",
    "#           0.412907   1.01672;\n",
    "#           1.41332   -0.918205;\n",
    "#           0.766647  -1.00445]';\n",
    "X = ens.S\n",
    "X = randn(Nx, Ne).^2 + 0.1*randn(Nx, Ne)\n",
    "# idx = [0 0; 0 1; 1 0; 0 2; 2 0; 1 1; 2 1; 1 2; 1 3; 2 2]\n",
    "\n",
    "# Nψ = 10\n",
    "\n",
    "# coeff = [     1.0174962905416995;\n",
    "#              -1.1871356902490515;\n",
    "#              -1.9837596947482932;\n",
    "#               0.5088563113730136;\n",
    "#              -0.9948770215816068;\n",
    "#               1.1697089852843865;\n",
    "#              -0.4364897348115606;\n",
    "#              -0.45195264571030846;\n",
    "#               0.6717865772395687;\n",
    "#               0.8540132401727857]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×1000 Array{Float64,2}:\n",
       " -0.690202   -0.595004    1.53707   …  -0.591998    -0.578563   1.52853\n",
       " -0.441275   -0.314905   -0.282054     -0.30521     -0.622784   0.690694\n",
       "  1.15504    -0.652401   -0.618832     -0.0466972   -0.4555    -0.691359\n",
       "  3.07661    -0.686147   -0.726459     -0.764043     0.390474   0.0371078\n",
       " -0.323856   -0.237024    0.167072     -0.611194    -0.624197   3.35201\n",
       "  1.53622    -0.640471   -0.284045  …  -0.0834316   -0.310722  -0.291826\n",
       " -0.131834    0.0363916   0.112176     -0.601238    -0.554947  -0.451961\n",
       " -0.352505    1.71733    -0.753808      0.469905    -0.345014  -0.141933\n",
       " -0.0696934   0.0338294  -0.336468     -0.00743629   1.11219   -0.688029\n",
       " -0.452564   -0.711301   -0.498921     -0.512323     0.983083  -0.73837"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = LinearTransform(X; diag = true)\n",
    "transform!(L, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×200 Array{Float64,2}:\n",
       " -0.733241  -0.588017   -0.570597   …  -0.591998    -0.578563   1.52853\n",
       " -0.504441   2.32238    -0.669967      -0.30521     -0.622784   0.690694\n",
       "  0.63604   -0.596369   -0.220347      -0.0466972   -0.4555    -0.691359\n",
       " -0.428104  -0.767242   -0.0572687     -0.764043     0.390474   0.0371078\n",
       "  0.287644  -0.37097     0.0700383     -0.611194    -0.624197   3.35201\n",
       " -0.102864   0.0141409  -0.687785   …  -0.0834316   -0.310722  -0.291826\n",
       " -0.232743  -0.752499   -0.475897      -0.601238    -0.554947  -0.451961\n",
       " -0.513879  -0.585413    0.42345        0.469905    -0.345014  -0.141933\n",
       " -0.400458  -0.638978   -0.599365      -0.00743629   1.11219   -0.688029\n",
       " -0.52674   -0.414987    2.33183       -0.512323     0.983083  -0.73837"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:,1:800]\n",
    "X_valid = X[:,801:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables\n",
      "  #unused#\u001b[36m::Core.Compiler.Const(AdaptiveTransportMap.var\"#greedyfit##kw\"(), false)\u001b[39m\n",
      "  @_2\u001b[36m::NamedTuple{(:verbose,),Tuple{Bool}}\u001b[39m\n",
      "  @_3\u001b[36m::Core.Compiler.Const(AdaptiveTransportMap.greedyfit, false)\u001b[39m\n",
      "  m\u001b[36m::Int64\u001b[39m\n",
      "  k\u001b[36m::Int64\u001b[39m\n",
      "  X\u001b[36m::Array{Float64,2}\u001b[39m\n",
      "  Xvalid\u001b[36m::Array{Float64,2}\u001b[39m\n",
      "  maxterms\u001b[36m::Int64\u001b[39m\n",
      "  maxpatience\u001b[36m::Int64\u001b[39m\n",
      "  verbose\u001b[36m::Bool\u001b[39m\n",
      "  @_11\u001b[36m::Int64\u001b[39m\n",
      "  @_12\u001b[36m::Bool\u001b[39m\n",
      "\n",
      "Body\u001b[91m\u001b[1m::Tuple{HermiteMapk{_A,_B,_C} where _C where _B where _A,Array{Float64,1},Array{Float64,1}}\u001b[22m\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m %1  = Base.haskey(@_2, :maxpatience)\u001b[36m::Core.Compiler.Const(false, false)\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #3 if not %1\n",
      "\u001b[90m2 ─\u001b[39m       Core.Compiler.Const(:(Base.getindex(@_2, :maxpatience)), false)\n",
      "\u001b[90m│  \u001b[39m       Core.Compiler.Const(:(%3 isa AdaptiveTransportMap.Int64), false)\n",
      "\u001b[90m│  \u001b[39m       Core.Compiler.Const(:(%4), false)\n",
      "\u001b[90m│  \u001b[39m       Core.Compiler.Const(:(goto %9), false)\n",
      "\u001b[90m│  \u001b[39m       Core.Compiler.Const(:(%new(Core.TypeError, Symbol(\"keyword argument\"), :maxpatience, AdaptiveTransportMap.Int64, %3)), false)\n",
      "\u001b[90m│  \u001b[39m       Core.Compiler.Const(:(Core.throw(%7)), false)\n",
      "\u001b[90m│  \u001b[39m       Core.Compiler.Const(:(@_11 = %3), false)\n",
      "\u001b[90m└──\u001b[39m       Core.Compiler.Const(:(goto %14), false)\n",
      "\u001b[90m3 ┄\u001b[39m %11 = Core.apply_type(Base.Val, 5)\u001b[36m::Core.Compiler.Const(Val{5}, false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %12 = (%11)()\u001b[36m::Core.Compiler.Const(Val{5}(), false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (@_11 = Base.literal_pow(AdaptiveTransportMap.:^, 10, %12))\n",
      "\u001b[90m│  \u001b[39m       (maxpatience = @_11)\n",
      "\u001b[90m│  \u001b[39m %15 = Base.haskey(@_2, :verbose)\u001b[36m::Core.Compiler.Const(true, false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       %15\n",
      "\u001b[90m│  \u001b[39m %17 = Base.getindex(@_2, :verbose)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %18 = (%17 isa AdaptiveTransportMap.Bool)\u001b[36m::Core.Compiler.Const(true, false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       %18\n",
      "\u001b[90m└──\u001b[39m       goto #5\n",
      "\u001b[90m4 ─\u001b[39m       Core.Compiler.Const(:(%new(Core.TypeError, Symbol(\"keyword argument\"), :verbose, AdaptiveTransportMap.Bool, %17)), false)\n",
      "\u001b[90m└──\u001b[39m       Core.Compiler.Const(:(Core.throw(%21)), false)\n",
      "\u001b[90m5 ┄\u001b[39m       (@_12 = %17)\n",
      "\u001b[90m└──\u001b[39m       goto #7\n",
      "\u001b[90m6 ─\u001b[39m       Core.Compiler.Const(:(@_12 = true), false)\n",
      "\u001b[90m7 ┄\u001b[39m       (verbose = @_12)\n",
      "\u001b[90m│  \u001b[39m %27 = (:maxpatience, :verbose)\u001b[36m::Core.Compiler.Const((:maxpatience, :verbose), false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %28 = Core.apply_type(Core.NamedTuple, %27)\u001b[36m::Core.Compiler.Const(NamedTuple{(:maxpatience, :verbose),T} where T<:Tuple, false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %29 = Base.structdiff(@_2, %28)\u001b[36m::Core.Compiler.Const(NamedTuple(), false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %30 = Base.pairs(%29)\u001b[36m::Core.Compiler.Const(Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}(), false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %31 = Base.isempty(%30)\u001b[36m::Core.Compiler.Const(true, false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       %31\n",
      "\u001b[90m└──\u001b[39m       goto #9\n",
      "\u001b[90m8 ─\u001b[39m       Core.Compiler.Const(:(Base.kwerr(@_2, @_3, m, k, X, Xvalid, maxterms)), false)\n",
      "\u001b[90m9 ┄\u001b[39m %35 = AdaptiveTransportMap.:(var\"#greedyfit#95\")(maxpatience, verbose, @_3, m, k, X, Xvalid, maxterms)\u001b[91m\u001b[1m::Tuple{HermiteMapk{_A,_B,_C} where _C where _B where _A,Array{Float64,1},Array{Float64,1}}\u001b[22m\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       return %35\n"
     ]
    }
   ],
   "source": [
    "@code_warntype greedyfit(m, Nx, X_train, X_valid, 15; verbose = false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "syntax: \"$\" expression outside quote",
     "output_type": "error",
     "traceback": [
      "syntax: \"$\" expression outside quote",
      "",
      "Stacktrace:",
      " [1] top-level scope at /home/mat/.julia/packages/IJulia/DrVMH/src/kernel.jl:52"
     ]
    }
   ],
   "source": [
    "@code_warntype greedyfit($m, $Nx, $X_train, $X_valid, $15; verbose = false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.001 s (1279836 allocations: 2.03 GiB)\n"
     ]
    }
   ],
   "source": [
    "@btime greedyfit($m, $Nx, $X_train, $X_valid, $10; verbose = false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000038 seconds (42 allocations: 120.516 KiB)\n",
      "1 terms - Training error: 1.4443504670380543, Validation error: 1.3147907978711455\n",
      "2 terms - Training error: 1.013555754394048, Validation error: 1.0148284980423214\n",
      "3 terms - Training error: 0.9740035731615574, Validation error: 0.9536709077333043\n",
      "4 terms - Training error: 0.968194963388136, Validation error: 0.9269258934472301\n",
      "5 terms - Training error: 0.8660654654774056, Validation error: 0.8538651976765612\n",
      "6 terms - Training error: 0.8468938234481649, Validation error: 0.8374329264723278\n",
      "7 terms - Training error: 0.8118015219715872, Validation error: 0.8007373200002506\n",
      "8 terms - Training error: 0.808988833791454, Validation error: 0.8016700608672841\n",
      "9 terms - Training error: 0.8055509920369043, Validation error: 0.8064967607768131\n",
      "10 terms - Training error: 0.7857644650326624, Validation error: 0.8090534466320567\n"
     ]
    }
   ],
   "source": [
    "Hk_old = HermiteMapk(m, Nx; α = 1e-6);\n",
    "\n",
    "@time S = Storage(Hk_old.I.f, X);\n",
    "\n",
    "Hk_new, train_error, valid_error = greedyfit(m, Nx, X_train, X_valid, 10; verbose = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000057 seconds (42 allocations: 120.516 KiB)\n",
      "1 terms - Training error: 1.41428818328749, Validation error: 1.435039932873401\n",
      "2 terms - Training error: 1.011647231546337, Validation error: 1.0765340323252046\n",
      "3 terms - Training error: 0.954187562314565, Validation error: 1.009496573370243\n",
      "4 terms - Training error: 0.9532824496069529, Validation error: 1.007776307368724\n",
      "5 terms - Training error: 0.841380513349966, Validation error: 0.9041126563257862\n",
      "6 terms - Training error: 0.8299467025145106, Validation error: 0.9037778557535633\n",
      "7 terms - Training error: 0.8018842783083129, Validation error: 0.8750517929963674\n",
      "8 terms - Training error: 0.801758584142784, Validation error: 0.8767880843281514\n",
      "9 terms - Training error: 0.8015539210804201, Validation error: 0.8774101595696208\n",
      "10 terms - Training error: 0.7995583928098936, Validation error: 0.8823916723449652\n"
     ]
    }
   ],
   "source": [
    "Hk_old = HermiteMapk(m, Nx; α = 1e-6);\n",
    "\n",
    "@time S = Storage(Hk_old.I.f, X);\n",
    "\n",
    "Hk_new, train_error, valid_error = greedyfit(m, Nx, X_train, X_valid, 10; verbose = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hk_test = deepcopy(Hk_new)\n",
    "setcoeff!(Hk_test, zero(getcoeff(Hk_new)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float64,1}:\n",
       " -11.217886066730607\n",
       "  11.50914577979369\n",
       "  26.61111083798624\n",
       " -24.71937861667548\n",
       "  34.997147393519235\n",
       " -17.03501613771925\n",
       "  11.077321531464895\n",
       "   0.034843907277600714\n",
       "   0.0381866111200113\n",
       "   0.1782552001411759"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_test = Storage(Hk_test.I.f, X_train)\n",
    "coeff_test = getcoeff(Hk_test)\n",
    "\n",
    "res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!(S_test, Hk_test, X_train)), coeff_test, Optim.BFGS())\n",
    "Optim.minimizer(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " -1.144117388080984"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = Optim.optimize(Optim.only_fg!(negative_log_likelihood!(S, Hk_old, ens.S)), coeff, Optim.BFGS())\n",
    "coeffopt = Optim.minimizer(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
